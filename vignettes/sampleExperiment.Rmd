---
title: "Sample experiment using Sliding Window Regression"
author: "Stefan Schrunner"
date: '2023-05-01'
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Sample experiment using Sliding Window Regression}
  %\VignetteEncoding{UTF-8}
---

# Introduction

<tt>SlidingWindowReg</tt> implements a regression model for hydrological time series data. In particular, multiple time-lagged windows with Gaussian kernel shape are estimated from training data. Then, each extracted feature is mapped to a target time series via multiple linear regression.

In this vignette, a sample experiment is performed to demonstrate that the model is able to identify model parameters correctly in a user-simulated setup.

## Data preparation \& experimental setup

First, we load the package and the sample watershed data:

```{r loading, message = FALSE}
library(SlidingWindowReg)

data("sampleWatershed")
```

As a second step, we divide the dataset into (a) a train set containing 30 years (77\% of the time series) and (b) a test set comprising the residual 9 years (23\% of the time series). Note that in the present dataset, <i>years</i> refer to hydrological years (October 01 to September 30).

```{r splits, warning=FALSE}
library(lubridate) # package to handle date formats
hydr_year <- cumsum(format(sampleWatershed$date, "%d.%m.") == "01.10.") # determine hydrological years (Oct 01 to Sep 30)

train_inds <- which(hydr_year <= 30)
```

# SlidingWindowReg model

Given the data splits, we train the <tt>SlidingWindowReg</tt> model on the train set. For this purpose, the following parameters are set:

* <tt>iter</tt> number of iterations (maximum number of windows)
* <tt>runs</tt> number of independent model runs --- by default, the run achieving the best performance metric is returned
* <tt>param\_selection</tt> method to determine the number of windows

## Model training

In the presented example, we use 3 iterations (up to 3 windows), 1 run, and determine the hyperparameter (number of windows $k$) with respect to the Bayesian Information Criterion (BIC). Further, we set the parallelization procedure to <tt>FALSE</tt>.

```{r execute}
mod <- trainSWR(sampleWatershed$rain[train_inds],
                sampleWatershed$gauge[train_inds],
                iter = 3,
                runs = 1,
                parallel = FALSE,
                param_selection = "best_bic")
```

## Parallelization

Model parallelization is implemented between the model runs, while iterations (incrementally adding windows in each iterations) run in a serial order. Hence, the option <tt>parallel = FALSE</tt> should be chosen if <tt>runs = 1</tt>. In case of multiple model runs, <tt>parallel</tt> can be set to either <tt>TRUE</tt> (in this case, the number of available kernels is determined automatically), or to a positive integer number indicating the number of kernels to be used.

# Evaluation

Tools for evaluating the model results include summary and plot functions for the model parameters, as well as metrics and plots to determine the predictive performance on test sets.

## Model parameters

A first overview on the model results can be obtained by printing a model summary:

```{r summary}
summary(mod)
```

In specific, the main model parameters are stored as:

* a matrix characterizing the location and size of the windows (column 1 indicates all center points on the time axis, column 2 indicates the variance)
* a vector of regression coefficients

```{r evaluate_param}
# window parameters
print(mod$param)

# regression parameters
print(mod$mix)
```

In order to visualize the estimated windows, a kernel plot is available in <tt>SlidingWindowReg</tt>:

```{r evaluate_param_plot, warning = FALSE, fig.width = 5, fig.height = 3, fig.align = 'center'}
coef(mod)

plot(mod, include_text = FALSE)
```

## Predictive performance

To assess its predictive performance, we evaluate the model on the test set. For this purpose, we compute the root mean squared error (RMSE) and further evaluation metrics:

```{r evaluate_rmse}
pred_on_test <- predict(mod, 
                        newdata = sampleWatershed$rain[-train_inds])

print(eval_all(pred_on_test, 
               sampleWatershed$gauge[-train_inds]))
```

As a next step, we generate a plot demonstrating 

* the input time series, 
* the predicted output time series, and 
* the ground truth output.

The plot demonstrates the first 3 and last 3 hydrological years (in this case, years 1-3 and 7-9 are displayed).

```{r evaluate_plot, fig.width = 7, fig.height = 7, fig.align = 'center'}
plot(mod, 
     type = "prediction",
     reference = sampleWatershed$gauge[-train_inds],
     newdata = sampleWatershed$rain[-train_inds])
```


